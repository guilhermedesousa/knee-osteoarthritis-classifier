{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJTlY9_nzSI1"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVuvTnIhx9TB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from skimage import exposure\n",
        "from tqdm import tqdm\n",
        "\n",
        "from skimage import exposure, filters, util\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from skimage.restoration import denoise_bilateral\n",
        "from skimage.filters import unsharp_mask\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage.util.dtype import img_as_ubyte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeQ9DcLYbPAM"
      },
      "source": [
        "## Getting the dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ud45ZmebDSV",
        "outputId": "e328e946-d5b9-4f7c-97a6-8a131f104cff"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppqMhcu8b--o"
      },
      "outputs": [],
      "source": [
        "dataset_root = '/content/drive/MyDrive/pgc'\n",
        "dataset_source = '/content/drive/MyDrive/pgc/koa_dataset_with_severity_grading'\n",
        "dataset_destination = '/content/drive/MyDrive/pgc/preprocessed_dataset'\n",
        "dataset_5_classes = '/content/drive/MyDrive/pgc/preprocessed_dataset_5_classes'\n",
        "dataset_2_classes = '/content/drive/MyDrive/pgc/preprocessed_dataset_2_classes'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxijjsV20VzO"
      },
      "source": [
        "## Checking the dataset properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivlfq1Dndn9J"
      },
      "outputs": [],
      "source": [
        "def calculate_class_frequencies(dataset_label, classes_to_exclude=[], dataset_path=dataset_5_classes):\n",
        "    class_frequencies = {}\n",
        "    total = 0\n",
        "    for kl_grade in range(5):\n",
        "        if kl_grade in classes_to_exclude:\n",
        "            continue\n",
        "        folder_path = f\"{dataset_path}/{dataset_label}/{kl_grade}\"\n",
        "        count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "        total += count\n",
        "        class_frequencies[kl_grade] = count\n",
        "\n",
        "    print(f\"Total of images={total}\")\n",
        "    return class_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "sTTjOQ3vzQo7",
        "outputId": "c9ae2c6a-1e84-4b13-b861-d148c7261510"
      },
      "outputs": [],
      "source": [
        "kl_grades = (\"0\", \"1\", \"2\", \"3\", \"4\")\n",
        "# kl_grades = (\"0\", \"2\", \"3\", \"4\")\n",
        "# kl_grades = (\"2\", \"3\", \"4\")\n",
        "# kl_grades = (\"0\", \"1\")\n",
        "\n",
        "classes_to_exclude = []\n",
        "\n",
        "class_frequencies = {\n",
        "    \"train\": calculate_class_frequencies(\"train\", classes_to_exclude),\n",
        "    \"test\": calculate_class_frequencies(\"test\", classes_to_exclude),\n",
        "    \"val\": calculate_class_frequencies(\"val\", classes_to_exclude),\n",
        "    \"calib\": calculate_class_frequencies(\"calib\", classes_to_exclude)\n",
        "}\n",
        "\n",
        "image_count = {\n",
        "    \"train\": tuple([v for k,v in class_frequencies[\"train\"].items()]),\n",
        "    \"test\": tuple([v for k,v in class_frequencies[\"test\"].items()]),\n",
        "    \"val\": tuple([v for k,v in class_frequencies[\"val\"].items()]),\n",
        "    \"calib\": tuple([v for k,v in class_frequencies[\"calib\"].items()])\n",
        "}\n",
        "\n",
        "print(image_count)\n",
        "\n",
        "x = np.arange(len(kl_grades))\n",
        "width = 0.20\n",
        "multiplier = 0\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for dataset, count in image_count.items():\n",
        "    offset = width * multiplier\n",
        "    rects = ax.bar(x + offset, count, width, label=dataset)\n",
        "    ax.bar_label(rects, padding=3)\n",
        "    multiplier += 1\n",
        "\n",
        "ax.set_ylabel('Número de imagens')\n",
        "ax.set_xlabel('Escala de KL')\n",
        "ax.set_title('Número de imagens por escala de KL')\n",
        "ax.set_xticks(x + width, kl_grades)\n",
        "ax.legend(loc='upper right', ncols=3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkE5-fZYn2zn",
        "outputId": "194b3a7d-c6c7-43ec-f11f-17b57818b59b"
      },
      "outputs": [],
      "source": [
        "folder_path = f\"{dataset_source}/train/4_augmented\"\n",
        "count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pBzIeWuy41x"
      },
      "source": [
        "### Balance the dataset using data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clEU5OzCfyxo"
      },
      "outputs": [],
      "source": [
        "def augment_class_folder(input_folder, output_folder, current_count, num_augmented_images=500, seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    total_original_images = len(image_files)\n",
        "\n",
        "    images_to_select = min(total_original_images, 100)  # Select at most 100 images to ensure variety\n",
        "    augmentations_per_image = int(np.ceil(num_augmented_images / images_to_select))\n",
        "\n",
        "    selected_images = random.sample(image_files, images_to_select)\n",
        "\n",
        "    print(f\"Selected {images_to_select} images for augmentation\")\n",
        "    print(f\"Will generate ~{augmentations_per_image} versions per selected image\")\n",
        "\n",
        "    # Define augmentation transforms\n",
        "    augmentation_transforms = [\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    ]\n",
        "\n",
        "    augmented_count = 0\n",
        "    pbar = tqdm(total=num_augmented_images, desc=\"Generating augmented images\")\n",
        "\n",
        "    # Process each selected image\n",
        "    while augmented_count < num_augmented_images:\n",
        "        for img_file in selected_images:\n",
        "            if augmented_count >= num_augmented_images:\n",
        "                break\n",
        "\n",
        "            input_path = os.path.join(input_folder, img_file)\n",
        "            img = Image.open(input_path).convert('RGB')\n",
        "\n",
        "            # Apply random combinations of transforms\n",
        "            augmented_img = img.copy()\n",
        "\n",
        "            # Randomly select 2-3 transforms\n",
        "            num_transforms = random.randint(2, 3)\n",
        "            selected_transforms = random.sample(augmentation_transforms, num_transforms)\n",
        "\n",
        "            for transform in selected_transforms:\n",
        "                augmented_img = transform(augmented_img)\n",
        "\n",
        "            # Save augmented image\n",
        "            base_name = os.path.splitext(img_file)[0]\n",
        "            output_path = os.path.join(\n",
        "                output_folder,\n",
        "                f\"{base_name}_aug.png\"\n",
        "            )\n",
        "            augmented_img.save(output_path, 'png', quality=100)\n",
        "\n",
        "            augmented_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "            if augmented_count >= num_augmented_images:\n",
        "                break\n",
        "\n",
        "    pbar.close()\n",
        "    return augmented_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oydFw6bpy-xX"
      },
      "outputs": [],
      "source": [
        "def augment_dataset(dataset_root, classes_to_augment, num_augmentations):\n",
        "    results = {}\n",
        "    print(f\"Augmenting {num_augmentations} images per class...\")\n",
        "\n",
        "    for class_num in classes_to_augment:\n",
        "        class_folder = os.path.join(dataset_root, 'train', f\"{class_num}\")\n",
        "        output_folder = os.path.join(dataset_root, 'train', f\"{class_num}\")\n",
        "\n",
        "        if not os.path.exists(class_folder):\n",
        "            print(f\"Warning: Folder for KL{class_num} not found at {class_folder}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nAugmenting KL{class_num} class...\")\n",
        "        class_counts = calculate_class_frequencies(\"train\")\n",
        "        current_count = class_counts[class_num]\n",
        "        augmented_count = augment_class_folder(\n",
        "            class_folder,\n",
        "            output_folder,\n",
        "            current_count,\n",
        "            num_augmentations)\n",
        "\n",
        "        results[class_num] = {\n",
        "            \"current_count\": current_count,\n",
        "            \"augmented_count\": augmented_count,\n",
        "            \"total_count\": current_count + augmented_count\n",
        "        }\n",
        "\n",
        "    print(\"\\nAugmentation Results:\")\n",
        "    print(\"-\" * 50)\n",
        "    for class_name, counts in results.items():\n",
        "        print(f\"\\n{class_name}:\")\n",
        "        print(f\"  Original images: {counts['current_count']}\")\n",
        "        print(f\"  Augmented images: {counts['augmented_count']}\")\n",
        "        print(f\"  Total images: {counts['total_count']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQa0ArZEWcM7"
      },
      "outputs": [],
      "source": [
        "augment_dataset(dataset_source, classes_to_augment=[1, 3, 4], num_augmentations=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kug65-Vnfxv"
      },
      "outputs": [],
      "source": [
        "def delete_augmented_images(dataset_root, classes_to_delete):\n",
        "    for class_num in classes_to_delete:\n",
        "        class_folder = os.path.join(dataset_root, 'train', f\"{class_num}\")\n",
        "        image_files = [f for f in os.listdir(class_folder) if \"_aug_\" in f]\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(class_folder, image_file)\n",
        "            os.remove(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LS-KZbGoB5t"
      },
      "outputs": [],
      "source": [
        "delete_augmented_images(dataset_source, classes_to_delete=[1, 3, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zFMYxjY34A7"
      },
      "source": [
        "## Testing preprocessing techniques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imaUBfC1PkrH"
      },
      "outputs": [],
      "source": [
        "def equalize_image(image):\n",
        "    # convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # apply histogram equalization\n",
        "    equalized_image = cv2.equalizeHist(gray_image)\n",
        "\n",
        "    return equalized_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiyvugMt2Wnk"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    # convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "\n",
        "    equalized = clahe.apply(gray_image)\n",
        "\n",
        "    return equalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDXbdfAbaUvY"
      },
      "outputs": [],
      "source": [
        "def print_image_histogram(image):\n",
        "    hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
        "    cdf = hist.cumsum()\n",
        "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
        "\n",
        "    plt.plot(cdf_normalized, color='b')\n",
        "    plt.hist(image.flatten(), 256, [0, 256], color='r')\n",
        "    plt.xlim([0, 256])\n",
        "    plt.legend(('cdf', 'histograma'), loc='upper left')\n",
        "    plt.ylabel('Número de pixels')\n",
        "    plt.xlabel('Intensidade de pixel')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEz47ybW8uie"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('/content/9001695L.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "tnbsjBXDX1ZW",
        "outputId": "f25b5021-b8d6-441f-e2d1-ec47bca43b8f"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(image)\n",
        "# print_image_histogram(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Xfp7MOe-9AZm",
        "outputId": "e4e28538-ade0-4b62-904f-f822ee8523d2"
      },
      "outputs": [],
      "source": [
        "equalized_image = equalize_image(image)\n",
        "# print_image_histogram(equalized_image)\n",
        "cv2_imshow(equalized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "9_Lct7BbRYkY",
        "outputId": "cd8919b7-3372-4c1d-94aa-7453112a9227"
      },
      "outputs": [],
      "source": [
        "processed_image = preprocess_image(image)\n",
        "cv2_imshow(processed_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3evrbly27D6o"
      },
      "source": [
        "## Preprocessing x-ray images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v3d4BL87Iez"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(dataset_label, src_path, dst_path):\n",
        "    for kl_grade in range(5):\n",
        "        src_folder = f\"{src_path}/{dataset_label}/{kl_grade}\"\n",
        "        dest_folder = f\"{dst_path}/{dataset_label}/{kl_grade}\"\n",
        "        os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "        image_files = [f for f in os.listdir(src_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "\n",
        "        for filename in tqdm(image_files, desc=f\"Processing KL grade {kl_grade} - {dataset_label}\"):\n",
        "            image_path = os.path.join(src_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            preprocessed_image = preprocess_image(image)\n",
        "            cv2.imwrite(os.path.join(dest_folder, filename), preprocessed_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTqcImSsVBWV",
        "outputId": "98f7eabb-020a-4423-8d0f-89c6a49497a0"
      },
      "outputs": [],
      "source": [
        "for dataset_label in [\"train\", \"test\", \"val\"]:\n",
        "    preprocess_dataset(dataset_label, dataset_source, dataset_destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBVODKpUvNE5"
      },
      "outputs": [],
      "source": [
        "def check_filenames(dataset_label, src_path, dst_path):\n",
        "    for kl_grade in range(5):\n",
        "        src_folder = f\"{src_path}/{dataset_label}/{kl_grade}\"\n",
        "        dest_folder = f\"{dst_path}/{dataset_label}/{kl_grade}\"\n",
        "        os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "        src_files = [f for f in os.listdir(src_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "        dest_files = [f for f in os.listdir(dest_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "\n",
        "        for filename in src_files:\n",
        "            if filename not in dest_files:\n",
        "                print(f\"Arquivo {filename} não encontrado em {dest_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe-fe_wAv8Sc"
      },
      "outputs": [],
      "source": [
        "for dataset_label in [\"train\", \"test\", \"val\"]:\n",
        "    check_filenames(dataset_label, dataset_source, dataset_destination)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLKEqpIiRsqX"
      },
      "source": [
        "## Duplicate dataset excluding classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K08JUP78R0_V"
      },
      "outputs": [],
      "source": [
        "def copy_dataset(classes_to_exclude, dataset_name, new_dataset_name, dataset_label):\n",
        "  for kl_grade in range(5):\n",
        "    if kl_grade in classes_to_exclude:\n",
        "      continue\n",
        "\n",
        "    src_folder = f\"{dataset_root}/{dataset_name}/{dataset_label}/{kl_grade}\"\n",
        "    dest_folder = f\"{dataset_root}/{new_dataset_name}/{dataset_label}/{kl_grade}\"\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(src_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "\n",
        "    for filename in tqdm(image_files, desc=f\"Copying KL grade {kl_grade} - {new_dataset_name}\"):\n",
        "        src_path = os.path.join(src_folder, filename)\n",
        "        dest_path = os.path.join(dest_folder, filename)\n",
        "        img = cv2.imread(src_path)\n",
        "        cv2.imwrite(dest_path, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Cx2-Z9THLh",
        "outputId": "26314915-ecbb-4c2f-b7b2-7f3b29c84f78"
      },
      "outputs": [],
      "source": [
        "for dataset_label in [\"train\", \"test\", \"val\"]:\n",
        "  copy_dataset(classes_to_exclude=[0,1], dataset_name=\"preprocessed_dataset_0\", new_dataset_name=\"preprocessed_dataset_3_classes\", dataset_label=dataset_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDUX3e9jTYmP"
      },
      "outputs": [],
      "source": [
        "def create_2_classes_dataset(dataset_name, new_dataset_name, dataset_label):\n",
        "  for kl_grade in range(5):\n",
        "    new_kl_grade = 0 if kl_grade <= 1 else 1\n",
        "\n",
        "    src_folder = f\"{dataset_root}/{dataset_name}/{dataset_label}/{kl_grade}\"\n",
        "    dest_folder = f\"{dataset_root}/{new_dataset_name}/{dataset_label}/{new_kl_grade}\"\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(src_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "\n",
        "    for filename in tqdm(image_files, desc=f\"Copying KL grade {kl_grade} - {new_dataset_name}\"):\n",
        "        src_path = os.path.join(src_folder, filename)\n",
        "        dest_path = os.path.join(dest_folder, filename)\n",
        "        img = cv2.imread(src_path)\n",
        "        cv2.imwrite(dest_path, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeCtUulAAV-l",
        "outputId": "fcaeeb21-0e09-466b-bb99-ac8c7424ae34"
      },
      "outputs": [],
      "source": [
        "for dataset_label in [\"train\", \"test\", \"val\"]:\n",
        "  create_2_classes_dataset(dataset_name=\"preprocessed_dataset_0\", new_dataset_name=\"preprocessed_dataset_2_classes\", dataset_label=dataset_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Txgg_X42Amf3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idN8G2Ytj2Pp"
      },
      "source": [
        "# Create a calibration set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqC1AaPxj4zP"
      },
      "outputs": [],
      "source": [
        "def create_calibration_set(dataset_name, dataset_label, classes_to_exclude=[]):\n",
        "  for kl_grade in range(5):\n",
        "    if kl_grade in classes_to_exclude:\n",
        "      continue\n",
        "\n",
        "    src_folder = f\"{dataset_root}/{dataset_name}/{dataset_label}/{kl_grade}\"\n",
        "    dest_folder = f\"{dataset_root}/{dataset_name}/calib/{kl_grade}\"\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(src_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "    calib_set_size = int(len(image_files) * 0.5)\n",
        "    calib_images = random.sample(image_files, calib_set_size)\n",
        "\n",
        "    for filename in tqdm(calib_images, desc=f\"Copying KL grade {kl_grade} - calib\"):\n",
        "        src_path = os.path.join(src_folder, filename)\n",
        "        dest_path = os.path.join(dest_folder, filename)\n",
        "        img = cv2.imread(src_path)\n",
        "        cv2.imwrite(dest_path, img)\n",
        "\n",
        "        # Remove the image from the original folder\n",
        "        os.remove(src_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGOLD1Uela1K",
        "outputId": "1755741f-8ac5-400d-ec31-bdf7b3e1e406"
      },
      "outputs": [],
      "source": [
        "create_calibration_set(dataset_name=\"preprocessed_dataset\", dataset_label=\"test\", classes_to_exclude=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_JhxhSCt5-k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
